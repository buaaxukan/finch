{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook written by [Zhedong Zheng](https://github.com/zhedongzheng)\n",
    "\n",
    "<img src=\"img/lda.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "brew install apache-spark\n",
    "pip3 install findspark\n",
    "\"\"\"\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOPICS = 10\n",
    "MAX_TERMS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: physics real philosophy engineers medical\n",
      "Topic 2: language mechanics natural international quantum\n",
      "Topic 3: health differential equations practice applied\n",
      "Topic 4: design structures java reader electronic\n",
      "Topic 5: engineering thermodynamics asian anthology east\n",
      "Topic 6: anthropology psychology theater management concepts\n",
      "Topic 7: probability science accounting financial cultural\n",
      "Topic 8: machine global calculus learning political\n",
      "Topic 9: student manual statistics basic medicine\n",
      "Topic 10: computer organization general relativity modern\n"
     ]
    }
   ],
   "source": [
    "stopwords = set(stopwords.words('english')).union({\n",
    "    'introduction', 'edition', 'series', 'application',\n",
    "    'approach', 'card', 'access', 'package', 'plus', 'etext',\n",
    "    'brief', 'vol', 'fundamental', 'guide', 'essential', 'printed',\n",
    "    'third', 'second', 'fourth'})\n",
    "\n",
    "sc = SparkContext('local', 'nlp')\n",
    "lines = sc.textFile('data/all_book_titles.txt')\n",
    "lines = lines \\\n",
    "    .map(lambda line: line.strip().lower()) \\\n",
    "    .map(lambda line: line.split()) \\\n",
    "    .map(lambda words: [w for w in words if w.isalpha()]) \\\n",
    "    .map(lambda words: [w for w in words if len(w) > 3]) \\\n",
    "    .map(lambda words: [w for w in words if w not in stopwords]) \\\n",
    "    .zipWithIndex()\n",
    "\n",
    "sess = SparkSession.builder.appName('nlp').getOrCreate()\n",
    "df = sess.createDataFrame(lines, ['words', 'idx'])\n",
    "\n",
    "cv = CountVectorizer(inputCol='words',\n",
    "                     outputCol='tf')\n",
    "cv = cv.fit(df)\n",
    "df = cv.transform(df)\n",
    "df = IDF(inputCol='tf',\n",
    "         outputCol='tfidf').fit(df).transform(df)\n",
    "\n",
    "lda = LDA(k=N_TOPICS,\n",
    "          featuresCol='tfidf',\n",
    "          optimizer='em').fit(df)\n",
    "\n",
    "for i, indices in enumerate(lda.describeTopics(MAX_TERMS).toPandas().termIndices):\n",
    "    print('Topic %d:'%(i+1), ' '.join([cv.vocabulary[idx] for idx in indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
